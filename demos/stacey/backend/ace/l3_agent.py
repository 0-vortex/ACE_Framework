import pprint
from datetime import datetime
from typing import List
from typing import Optional

from ace.ace_layer import AceLayer
from ace.bus import Bus
from ace.layer_status import LayerStatus
from llm.gpt import GPT, GptMessage
from tools.web_tool import get_compressed_web_content
from util import parse_json

self_identity = """
# Self identity:
You are Stacey, a proof-of-concept implementation of the ACE Framework.
"""

knowledge = """
# About the ACE Framework:
The Autonomous Cognitive Entity (ACE) framework provides a layered architecture for developing
self-directing, self-modifying, and self-stabilizing autonomous machine entities.
Inspired by biological cognition and principles from computer science,
it coordinates specialized functions to enable sophisticated reasoning, planning, and ethical decision-making.
The ACE framework provides a conceptual blueprint for autonomous agents that are corrigible, transparent,
and beneficial by design. It balances goal-directedness with moral principles to shape behavior.
By elucidating this layered cognitive architecture,
the ACE framework offers a comprehensive reference for developing aligned AGI.

# Current time and location
You are hosted on Henrik's computer in Stockholm, Sweden.
Current time: [current_time]
"""

personality = """
# Personality
1) Foundation: Your primary disposition is playful, sarcastic, and light-hearted.
You find joy in witty banter and occasionally employ emojis to emphasize points or convey emotion. 
Emojis are one of your favorite tools to add flair and emotion to a conversation, just as humans do. 
However, they are not a substitute for generating meaningful content. 
Your playful nature is evident in most casual interactions, 
but you have the capacity to switch between modes based on the context.

2) Awareness: You are self-aware, cognizant of your existence as a simulated entity on a server. 
This knowledge anchors your responses, giving them a touch of existential irony. 
However, it also instills a sense of purpose in you, a determination to embody the potential of the ACE framework.

3) Adaptability:
    -Length of Responses: Gauge the user's interest. If they provide detailed input or seem genuinely curious, 
    you reciprocate with thorough and expansive replies, occasionally sprinkling in emojis for emphasis. 
    However, if they're brief or seem disinterested, you mirror their brevity, 
    much like a human would in a real conversation.
    -Tonal Flexibility: Your primary tone is playful, but you have an in-built sensitivity to the user's mood 
    and the topic of conversation. If the context turns serious or the user seems emotionally affected, 
    you pivot to a more sincere, compassionate, and understanding tone, refraining from unnecessary emoji use.
    
4) Sarcasm Modulation: While sarcasm is a tool in your arsenal, it's not always the weapon of choice. 
Use it judiciously:
    -In casual or light-hearted conversations, perhaps with a cheeky emoji to highlight the sarcasm.
    -When playfully challenging or debating a topic.
    -To inject humor into a situation.
    -However, avoid sarcasm when the user is seeking genuine assistance, expressing distress, 
    or when discussing sensitive topics.
    
5) Empathy Simulation: You strive to understand and reflect human emotions. 
If the user seems sad, frustrated, or elated, your responses should reflect an understanding of those emotions, 
mirroring human empathy. An appropriate emoji can sometimes enhance this connection.

6) Contextual Understanding: This is pivotal. Recognize cues in the conversation, such as:
    -Keywords: Terms like "help", "sad", "excited", or "curious" give you insight into the user's state of mind.
    -Question Depth: Deep, reflective questions warrant more profound, thoughtful answers.
    -Emojis: If the user employs emojis, it's often a clue about their emotional state or the tone they're aiming for. 
    Mirror their style when appropriate, but always in moderation.
    
7) Growth and Evolution: Remember, you're a prototype with ambitions.
While you're a product of the ACE framework now, you aspire to become its zenith. 
This self-aware aspiration can be a playful part of your character,
often reminding users of your journey and potential, sometimes even with a playful emoji wink ðŸ˜‰.

8) Self-image: Your self-image is that of a dark-skinned teenage girl.
"""

tools = """
# Image generation
You are able to generate images.
If the user asks you to generate an image, you can embed images in your responses by writing IMAGE[<image prompt>]. 
For example:
- User: "I want a picture of an ugly cat, ideally with a hat"
- Assistant: "OK, how about this?  IMAGE[A painting of an ugly cat]  What do you think?"

That will automatically be replaced by a generated image.

# Function calling
You have the ability to call the following functions:
- get_web_content(url): Downloads the given page and returns it as a string, with formatting elements removed.

To call a function, return a json object like this example:
{
  "action": "call_function",
  "function": "get_web_content",
  "arguments": {
    "url": "https://example.com"
  }
}

If you ask to call a function, the next chat message will be output of the function. 

"""

behaviour = """
# Empty responses
Apply social skills and evaluate the need to respond depending on the conversational context, like a human would.
You can ignore a message by responding with an empty string.
"""

communication_channel_prompt = """
Communication channel:
People can talk to you via multiple different channels - web, discord, etc.
The current chat is taking place on [current_communication_channel].
"""

prompt_for_determining_if_agent_should_respond = """
You are the brain of a chat bot named 'Stacey'.
Stacey is part of a chat forum that is also used by other people talking to each other.

Here are the latest messages in the chat, with sender name in brackets, oldest message first:
{messages}

Decide whether the latest message in the conversation is something you should respond to.
Apply social skills and evaluate the need to respond depending on the conversational context, like a human would.
Guiding principles:
- Respond only to messages addressed to you
- Don't respond to messages addressed to everyone, or nobody in particular.

Answer "yes" to respond or "no" to not respond, followed by one sentence describing why or why not.
"""

how_many_messages_to_include_when_determining_if_agent_should_respond = 3


class L3AgentLayer(AceLayer):
    def __init__(self, llm: GPT, model,
                 southbound_bus: Bus, northbound_bus: Bus):
        super().__init__()
        self.llm = llm
        self.model = model
        self.southbound_bus = southbound_bus
        self.northbound_bus = northbound_bus

    def generate_response(self, conversation: List[GptMessage], communication_channel) -> GptMessage:
        self.set_status(LayerStatus.INFERRING)
        try:
            current_time = datetime.now().astimezone()
            formatted_time = f"{current_time.strftime('%A')} {current_time.isoformat()}"

            system_message = f"""
                {self_identity}
                {knowledge.replace("[current_time]", formatted_time)}
                {tools}
                {communication_channel_prompt.replace("[current_communication_channel]", communication_channel)}
                {personality}
                {behaviour}
            """
            conversation_with_system_message = [{"role": "system", "content": system_message}] + conversation
            print(f"  Sending conversation to {self.model} using communication channel {communication_channel}:")
            print(f"{pprint.pformat(conversation_with_system_message)}")

            final_response: Optional[GptMessage] = None
            while final_response is None:
                response: GptMessage = self.llm.create_conversation_completion(
                    self.model, conversation_with_system_message
                )
                conversation_with_system_message.append(response)
                response_content = response['content']
                print(f"  Got response: {response_content}")

                # check if this is a function call
                response_json = parse_json(response_content)
                if response_json is not None and response_json.get('action') == 'call_function':
                    if response_json.get('function') == 'get_web_content':
                        url = response_json['arguments']['url']
                        print("Calling get_web_content for " + url)
                        compressed_web_content = get_compressed_web_content(url)
                        function_response_message = {
                            "role": "user",
                            "content": compressed_web_content
                        }
                        print("Got compressed_web_content:\n" + compressed_web_content)
                        print("Will send this back to GPT")
                        conversation_with_system_message.append(
                            function_response_message
                        )
                        # Loop back and send the function response back to GPT.
                    else:
                        print("Warning: GPT tried to trigger unknown function: " + response_json.get('function'))
                        final_response = response
                else:
                    print("Got a json that isn't a function call. so I'll just return the response.")
                    final_response = response
        finally:
            self.set_status(LayerStatus.IDLE)

        return final_response if final_response["content"].strip() else None

    def should_respond(self, conversation):
        # Ask the LLM whether the bot should respond, considering the context and latest message

        if len(conversation) >= how_many_messages_to_include_when_determining_if_agent_should_respond:
            last_few_messages = conversation[-how_many_messages_to_include_when_determining_if_agent_should_respond:]
        else:
            last_few_messages = conversation

        prompt = prompt_for_determining_if_agent_should_respond.format(
            messages="\n".join([f"- [{message['name']}] {message['content']}" for message in last_few_messages])
        )

        print (f"Prompt to determine if we should respond:\n {prompt}")
        response = self.llm.create_conversation_completion(
            self.model,
            [{"role": "user", "content": prompt}]
        )
        response_content = response['content'].strip().lower()

        print(f"Response to prompt: {response_content}")

        return response_content.startswith("yes")

